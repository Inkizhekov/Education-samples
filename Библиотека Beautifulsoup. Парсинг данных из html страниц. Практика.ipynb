{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Библиотека Beautifulsoup. Парсинг данных из html страниц. Практика.ipynb","provenance":[],"authorship_tag":"ABX9TyPmQRIu+ivMUNArDGezQvCy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","###План"],"metadata":{"id":"n0B8RA0YVpZG"}},{"cell_type":"markdown","source":["\n","1. Импорт библиотек\n","2. Получить список адресов по которым будет выполняться парсинг\n","3. Написать функцию парсинга и пополнения списков\n","4. Сохранить файл в csv\n"],"metadata":{"id":"BlZD7rMCVgAg"}},{"cell_type":"markdown","source":["###Импорт библиотек"],"metadata":{"id":"VGx1eo53Y5GK"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"XM7Ur6o8VOfd","executionInfo":{"status":"ok","timestamp":1660449899713,"user_tz":-420,"elapsed":869,"user":{"displayName":"Анатолий Инкижеков","userId":"04854426355593330927"}}},"outputs":[],"source":["import requests # обращение к данным по ссылке\n","from bs4 import BeautifulSoup #поиск на сайте и парсинт\n","import numpy as np # для работы с массивами\n","import pandas as pd #для создания DataFrame\n","import time"]},{"cell_type":"code","source":["# Получить список url\n","url = 'https://habr.com/ru'\n","firstPage = 682000 #первый пост в поиске\n","lastPage = 682010 #последний пост в поиске\n","\n","#функция перебора страниц и добавления в список\n","def get_urls():\n","  listUrl = [] # пустой список\n","  for page in range(firstPage,lastPage):\n","     pageUrl = '{}/post/{}'.format(url, page)\n","     listUrl.append(pageUrl)\n","  return listUrl #возвращаем заполненный список\n","  "],"metadata":{"id":"JZ8NnMQ7aEOs","executionInfo":{"status":"ok","timestamp":1660449899713,"user_tz":-420,"elapsed":12,"user":{"displayName":"Анатолий Инкижеков","userId":"04854426355593330927"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#количество ссылок\n","len(get_urls())\n","#get_urls()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttJcXV2NgfxG","executionInfo":{"status":"ok","timestamp":1660449899714,"user_tz":-420,"elapsed":13,"user":{"displayName":"Анатолий Инкижеков","userId":"04854426355593330927"}},"outputId":"7db3e482-e270-444c-d707-77ae4cb68bd2"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["###Написание функции парсинга и пополнения списков"],"metadata":{"id":"t1YcMj4dg5mT"}},{"cell_type":"code","source":["# Создаем пустые списки куда будем направлять информацию с сайта\n","titleList = [] #Добавляем заголовки\n","categoriesList = [] # список категорий\n","postList = [] # создаем пустой список для постов\n","karmaLIst = [] # Список для кармы\n","ratingList = [] # список для рейтингов\n","\n","def get_data():\n","  for pageData in get_urls():\n","    fullData = requests.get(pageData)\n","\n","    if fullData.status_code == 200: # статус 200 успешный отклик страницы\n","      print('ok')\n","      soup = BeautifulSoup(fullData.text,'html5lib') # парсинг страницы сайта\n","\n","      titles = soup.findAll('h1', class_ = 'articleTitle') # парсим заголовки\n","      for title in range(len(titles)):\n","        if titles[title].find('span', class_ = 'tm-article-snippet__title tm-article-snippet__title_h1'\n","                              ) is not None: \n","          titleList.append(titles[title].text.replace('!', ' ')\\\n","                                             .replace('-', '')\\\n","                                             .replace('-', '')\\\n","                                             .lower().strip())\n","            \n","      categories = soup.find_all(class_ = 'tm-article-snippet__hubs-item-link')\n","      for category in range(len(categories)): \n","        if categories[category].find('span', #class_ = 'tm-article-snippet__title tm-article-snippet__title_h1'\n","                              ) is not None: \n","        \n","          categoriesList.append(categories[category].text.replace('!', ' ')\\\n","                                             .replace('-', '')\\\n","                                             .replace('-', '')\\\n","                                             .lower().strip())\n","\n","      posts = soup.find_all(class_ = 'article-formatted-body article-formatted-body article-formatted-body_version-1')\n","      for post in range(len(posts)): \n","        if posts[post].find('div', #class_ = 'article-formatted-body article-formatted-body article-formatted-body_version-1'\n","                              ) is not None: \n","        \n","          postList.append(posts[post].text.replace('!', ' ')\\\n","                                             .replace('-', '')\\\n","                                             .replace('-', '')\\\n","                                             .lower().strip())\n","\n","      karmas = soup.find_all('a', class_ = 'tm-karma__votes tm-karma__votes_positive')\n","      for karma in range(len(karmas)): \n","        if karmas[karma].find('div', #class_ = 'tm-karma__votes tm-karma__votes_positive'\n","                              ) is not None: \n","        \n","          karmaLIst.append(karmas[karma].text)\n","      \n","      ratings = soup.find_all('a', class_ = 'tm-rating__counter tm-rating__counter')\n","      for rating in range(len(ratings)): \n","        if ratings[rating].find('div', #class_ = 'tm-rating__counter tm-rating__counter'\n","                              ) is not None: \n","        \n","          ratingList.append(ratings[rating].text)\n","\n","      time.sleep(1.0) # пауза для обхода блокировки парсинга\n","      \n","      \n","  return titleList, categoriesList, postList, karmaLIst, ratingList\n","     \n","\n","\n","\n","     \n"],"metadata":{"id":"uSqBhaoagzzT","executionInfo":{"status":"ok","timestamp":1660450067386,"user_tz":-420,"elapsed":337,"user":{"displayName":"Анатолий Инкижеков","userId":"04854426355593330927"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"fSZAiSOOS1ko"}},{"cell_type":"code","source":["get_data()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wf9SjTcnRtTO","executionInfo":{"status":"ok","timestamp":1660450087081,"user_tz":-420,"elapsed":15559,"user":{"displayName":"Анатолий Инкижеков","userId":"04854426355593330927"}},"outputId":"2ecd2076-fc78-4012-91a4-5ad3cb5b3954"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["ok\n","ok\n","ok\n","ok\n","ok\n"]},{"output_type":"execute_result","data":{"text/plain":["([],\n"," ['информационная безопасность *',\n","  'itинфраструктура *',\n","  'сетевые технологии *',\n","  'itкомпании',\n","  'блог компании uahosting.company',\n","  'управление персоналом *',\n","  'карьера в itиндустрии',\n","  'блог компании vk',\n","  'научнопопулярное'],\n"," ['10 августа 2022 года cisco подтвердила факт взлома своих корпоративных систем. инцидент с проникновением и развёртыванием зловредного по внутри периметра организации произошёл в конце мая. хакеры утверждают, что похитили 2,75 гб данных из сети компании, включая конфиденциальные документы и технологические чертежи сетевых устройств.\\n\\ncisco сообщила, что злоумышленники смогли скопировать неконфиденциальные данные, к которым был доступ у взломанной учётной записи сотрудника.\\n\\nсписок части из, якобы, украденных файлов с серверов cisco.\\n\\nэксперты cisco talos рассказали, что хакеры получили доступ к сети cisco, используя украденные учётные данные сотрудника после взлома его личной учётной записи google, которая была синхронизирована для входа во внутреннюю сеть через браузер. причем хакеры в процессе атаки убедили сотрудника cisco назвать им данные из пушуведомления системы многофакторной аутентификации (mfa) с помощью голосовой фишинговой атаки, выдав себя за сотрудника техподдержки компании.\\n\\nпосле этого хакеры смогли получить доступ к vpn компании через учётку пользователя. потом злоумышленники попытались распространить в корпоративной сети инструменты вирусашифровальщика yanluowang. им удалось это сделать на некоторых серверах и контроллерах домена citrix. «они перешли в среду citrix, скомпрометировав ряд серверов, и в конечном итоге получили привилегированный доступ к контроллерам домена», — пояснили в cisco talos.\\n\\nполучив права администратора домена, хакеры использовали специальное по и инструменты ntdsutil, adfind и secretsdump для сбора дополнительной информации. злоумышленники смогли развернуть на скомпрометированных серверах несколько зловредов, включая бэкдор.\\n\\nчерез некоторое время эксперты cisco обнаружили вторжение, изолировали доступ хакерам и вытеснили их из корпоративной среды. в течение нескольких недель хакеры продолжали попытки восстановить доступ к внутренним системам компании.\\n\\n«после получения первоначального доступа злоумышленники предприняли ряд действий для его скрытого сохранения, сведя к минимуму наличие артефактов и подозрительных логов в скомпрометированных системах», — пояснили в cisco talos. эксперты компании смогли обнаружить и удалить все зловреды, но хакеры успели скачать некоторые файлы из внутренней сети. в компании пояснили, что в ходе атаки никакие файлы на серверах зашифрованы или удалены не были.\\n\\nхакеры рассказали bleeping computer, что смогли похитить около 3100 файлов, включая документы партнёров с соглашениями о неразглашении, дампы данных и технические чертежи. они собираются опубликовать эту информацию, если компания не выплатит выкуп.'],\n"," [],\n"," [])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":[""],"metadata":{"id":"mJcIFVnESG-6","executionInfo":{"status":"ok","timestamp":1660450098666,"user_tz":-420,"elapsed":309,"user":{"displayName":"Анатолий Инкижеков","userId":"04854426355593330927"}}},"execution_count":10,"outputs":[]}]}